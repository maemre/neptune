\section{Conclusion} \label{conclusion}

We observed an up to $1.95\times$ increase in performance in terms of \% time spent in GC and on average $1.5\times$ throughput by implementing a parallel garbage collector.
Using a language with static safety guarantees (Rust) helped implementing parallelization correctly by catching non-thread safe accesses in compile time.

In the future, implementing the lazy sweeping algorithm mentioned in Evaluation section would be a good direction to take (it is a rather low-hanging fruit that just requires some more time to implement, unfortunately we didn't have enough time to implement it before deadline).
Another future improvement is designing a better load balancing method (like keeping a thread-local counter for work being done) to divide the work into more even chunks and to increase parallelization further.
We are planning to try other thread-safe stack algorithms to implement the mark stack due to Treiber stack not scaling well under high loads.
Having a more adaptive garbage collection algorithm that makes decisions about parallelization based on past data about live objects would be an interesting direction to follow.
Such an algorithm can adaptively choose parallelization based on an estimation of the size of the object graph being walked, e.g. a simplistic approach would be parallelizing only when doing a full collection or keeping track of ratio of live data to allocated memory after each marking to make an estimation.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "report"
%%% End:
